{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f124aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as Image\n",
    "import tensorflow as tf\n",
    "#from skimage import transform\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e607dfb",
   "metadata": {},
   "source": [
    "# Data import & Pre-processing --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6396e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets paths for images \n",
    "def get_catalog(file):\n",
    "    species = []\n",
    "    pics = []\n",
    "    for root, subdir, files in os.walk(file):\n",
    "        species.append(subdir)\n",
    "        pics.append(files)\n",
    "    species = species[0]\n",
    "    \n",
    "    catalog = {}\n",
    "    for i in range(len(species)):\n",
    "        catalog[species[i]] = pics[i+1]\n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9661f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(picture, save_loc,name):\n",
    "    #flip_2 = tf.image.flip_up_down(picture)\n",
    "    #cv2.imwrite(save_loc + name[:-4] + 'a.jpg', np.array(flip_2))\n",
    "    #flip_3 = tf.image.flip_left_right(picture)\n",
    "    #cv2.imwrite(save_loc + name[:-4] + 'b.jpg', np.array(flip_3))\n",
    "    #flip_4 = tf.image.flip_up_down(flip_3)\n",
    "    #cv2.imwrite(save_loc + name[:-4] + 'c.jpg', np.array(flip_4))\n",
    "    if len(name) == 7:\n",
    "        #rot_90 = tf.image.rot90(picture, k=1)\n",
    "        #cv2.imwrite(save_loc + name[:-4] + 'd.jpg', np.array(rot_90))\n",
    "        rot_180 = tf.image.rot90(picture, k=3)\n",
    "        cv2.imwrite(save_loc + name[:-4] + 'e.jpg', np.array(rot_180))\n",
    "        #rot_2 = tf.image.rot90(flip_3, k=1)\n",
    "        #cv2.imwrite(save_loc + name[:-4] + 'f.jpg', np.array(rot_2))\n",
    "        #rot_3 = tf.image.rot90(flip_3, k=3)\n",
    "        #cv2.imwrite(save_loc + name[:-4] + 'g.jpg', np.array(rot_3))\n",
    "       #rot = transform.rotate(picture, angle=45, mode='reflect')\n",
    "       #plt.imshow(rot)\n",
    "       #plt.show()\n",
    "       #rot1 = transform.rotate(rot, angle=90, mode='reflect')\n",
    "       #plt.imshow(rot1)\n",
    "       #plt.show()\n",
    "       #rot2 = transform.rotate(rot1, angle=90, mode='reflect')\n",
    "       #plt.imshow(rot2)\n",
    "       #plt.show()\n",
    "       #rot3 = transform.rotate(rot2, angle=90, mode='reflect')\n",
    "       #plt.imshow(rot3)\n",
    "       #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd330fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pics(catalog,path, species_index,pic_index, size):\n",
    "    count = 1\n",
    "    new_catalog = {}\n",
    "    names = []\n",
    "    for specie in catalog:\n",
    "        images =[]\n",
    "        for i in range(pic_index):\n",
    "            image = cv2.imread(path + specie + '/' + catalog[specie][i])\n",
    "            #data_augmentation(image,path + specie + '/',catalog[specie][i])\n",
    "            res = cv2.resize(image, dsize=size, interpolation=cv2.INTER_NEAREST)\n",
    "            images.append(res.flatten())\n",
    "        new_catalog[specie] = np.array(images)\n",
    "        names.append(specie[1:])\n",
    "        if count == species_index:\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "    return new_catalog, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224cef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_pics2(path, nspec, npic,shape):\n",
    "    bird_catalog = get_catalog(path)\n",
    "    pics, spec_names = get_pics(bird_catalog,path, nspec, npic,shape)\n",
    "    return pics, spec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92383a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Xy(pictures):\n",
    "    test_images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for species, values in pictures.items():\n",
    "        if len(test_images) == 0:\n",
    "            test_images = values\n",
    "            labels = np.repeat(count,values.shape[0])\n",
    "        else:\n",
    "            test_images = np.concatenate((test_images,values),axis=0)\n",
    "            labels = np.concatenate((labels, np.repeat(count, values.shape[0])),axis=0)\n",
    "        count +=1\n",
    "    test_images = np.array(test_images)\n",
    "    return test_images, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction(X):\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(random_state=seed).fit(X)\n",
    "    new_X = pca.transform(X)\n",
    "    print(\"Dim reduction ready.\")\n",
    "    return new_X, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51829477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction_kernelcosine(X):\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    kpca = KernelPCA(kernel='cosine',random_state=seed).fit(X)\n",
    "    new_X = kpca.transform(X)\n",
    "    print(\"Kernel PCA cosine ready\")\n",
    "    return new_X, kpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67476861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for data preprocessing ----------------------------------------------------------------------------------\n",
    "seed = 2\n",
    "np.random.RandomState(seed)\n",
    "\n",
    "#Declare variables \n",
    "train_file, valid_file, test_file = 'data/birds/train/', 'data/birds/valid/', 'data/birds/test/'\n",
    "num_species = 5\n",
    "num_pics_train, num_pics_val, num_pics_test = 120, 5, 5\n",
    "size = (64,64)\n",
    "\n",
    "#get pictures\n",
    "train_pictures, species_names = import_pics2(train_file, num_species, num_pics_train,size)\n",
    "valid_pictures, _ = import_pics2(valid_file, num_species, num_pics_val,size)\n",
    "test_pictures, _ = import_pics2(test_file, num_species, num_pics_test,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf40e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(species_names)\n",
    "species_names[0] = 'BLACK BROADBILL'\n",
    "#species_names[8] ='GROUND HORNBILL'\n",
    "#species_names[9] = 'CROWNED CRANE'\n",
    "#species_names[10] = 'EMERALD CUCKOO'\n",
    "#species_names[11] = 'FIREFINCH'\n",
    "#species_names[12] = 'OYSTER CATCHER'\n",
    "print(species_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2803c06",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigendecomposition(images):\n",
    "    species_values = {}\n",
    "    for specie, values in images.items():\n",
    "        mean = np.mean(values,axis=0)\n",
    "        x = (values-mean)/ 255\n",
    "        U, S, V = np.linalg.svd(x.T,full_matrices=False)\n",
    "        species_values[specie] = [U, S, mean, x]\n",
    "    print(\"Done eigendecomposing.\")\n",
    "    return species_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance(catalog,n_spec):\n",
    "    count = 0\n",
    "    for spec, vals in catalog.items():\n",
    "        eigenvalues = np.sum(np.diag(vals[1]),axis=0)\n",
    "        total = np.sum(eigenvalues)\n",
    "        eigenvalues_norm = eigenvalues/total\n",
    "        \n",
    "        meanbird = np.reshape(vals[2],(1,12288))\n",
    "        meanbird = np.reshape(meanbird.astype(np.uint8),(64,64,3))\n",
    "        plt.imshow(meanbird)\n",
    "        plt.show()\n",
    "        cv2.imwrite('plots/meanbird-{}.jpg'.format(spec[1:4]), np.array(meanbird))\n",
    "        \n",
    "        eigenbird = np.reshape(vals[0][:,2],(1,12288))\n",
    "        eigenbird = np.reshape(((eigenbird * 255)).astype(np.uint8),(64,64,3))\n",
    "        plt.imshow(eigenbird)\n",
    "        plt.show()\n",
    "        cv2.imwrite('plots/eigenbird-{}.jpg'.format(spec[1:4]), eigenbird)\n",
    "        \n",
    "        plt.scatter(np.arange(0, eigenvalues.shape[0]), eigenvalues_norm*100)\n",
    "        plt.title(spec[1:])\n",
    "        plt.xlabel('Principal Components')\n",
    "        plt.ylabel('Variance percentage')\n",
    "        plt.savefig('plots/variance-{}.jpg'.format(spec[1:4]))\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        count += 1\n",
    "        if count == n_spec:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eigenspecies(eigen,n_comp):\n",
    "    species_eigenvectors = {}\n",
    "    for spec, vals in  eigen.items():\n",
    "        U = vals[0]\n",
    "        mean = vals[2]\n",
    "        x = vals[3]\n",
    "        eigenvs =  U[:,:n_comp]\n",
    "        species_eigenvectors[spec] = (eigenvs, mean, x)\n",
    "    print(\"Done getting eigenspecies.\")\n",
    "    return species_eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residuals(eigenspecies,test):\n",
    "    residuals_matrix = []\n",
    "    test = test / 255\n",
    "    matrix_residual = []\n",
    "    for image in test:\n",
    "        per_species_residual = []\n",
    "        for specie, metrics in eigenspecies.items():\n",
    "            pre_image = image - (metrics[1]/255)\n",
    "            residual = np.linalg.norm(pre_image - (metrics[0] @ metrics[0].T @ pre_image))**2\n",
    "            per_species_residual.append(residual)\n",
    "        matrix_residual.append(per_species_residual) \n",
    "    print(\"Done getting residuals.\")\n",
    "    return np.array(matrix_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "eigenvectors = eigendecomposition(train_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714711ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance(eigenvectors,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenspecies = get_eigenspecies(eigenvectors, 90)\n",
    "X_test, y_test = get_Xy(test_pictures)\n",
    "residuals = get_residuals(eigenspecies,X_test)\n",
    "end = time.time()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = residuals.argmin(axis=1)\n",
    "print(accuracy_score(y_test,classification))\n",
    "print(classification_report(y_test,classification,target_names=species_names))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test,classification)\n",
    "cf = ConfusionMatrixDisplay(cf_matrix, display_labels= species_names)\n",
    "cf.plot(xticks_rotation='vertical')\n",
    "plt.savefig('plots/dim-red-cf.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ec464",
   "metadata": {},
   "source": [
    "# Density Estimation -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cluster label to classification label. \n",
    "def retrieve_info(cluster_labels,y_train):\n",
    "    reference_labels = {}\n",
    "    for i in range(len(np.unique(cluster_labels))):\n",
    "        index = np.where(cluster_labels == i,1,0)\n",
    "        num = np.bincount(y_train[index==1]).argmax()\n",
    "        reference_labels[i] = num\n",
    "    return reference_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eaadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Kmeans model and dictionary of labels. \n",
    "def k_means(seed,num_clust,X,y):\n",
    "    clf_km = KMeans(n_clusters=num_clust,random_state=seed).fit(X)\n",
    "    map_kmlabels = retrieve_info(clf_km.labels_,y)\n",
    "    return map_kmlabels, clf_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_Xy(train_pictures)\n",
    "X_val, y_val = get_Xy(valid_pictures)\n",
    "X_test, y_test = get_Xy(test_pictures)\n",
    "\n",
    "#scale_X_train, kpc = dim_reduction_kernelcosine(X_train)\n",
    "#scale_X_val = kpc.transform(X_val)\n",
    "#scale_X_test = kpc.transform(X_test)\n",
    "\n",
    "scale_X_train, scale_X_val, scale_X_test = (X_train/255).astype('float32'), (X_val/255).astype('float32'), (X_test/255).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da18c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scale_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run\n",
    "accuracy = []\n",
    "cluster = np.arange(115,400,25)\n",
    "\n",
    "start = time.time()\n",
    "for i in cluster:\n",
    "    mapping, model = k_means(seed, i, scale_X_train, y_train)\n",
    "    pred = model.predict(scale_X_val)\n",
    "    translated_pred = [mapping[i] for i in pred]\n",
    "    accuracy.append(accuracy_score(translated_pred, y_test))\n",
    "    print('Iteration ' + str(i) + \" complete.\")\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfcff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cluster, accuracy)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Validation by Number of Clusters')\n",
    "plt.savefig('plots/den-est-valid.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, model = k_means(seed, int(np.sqrt(scale_X_train.shape[0]/2)), scale_X_train, y_train)\n",
    "pred1 = model.predict(scale_X_train)\n",
    "pred2 = model.predict(scale_X_test)\n",
    "translated_pred1 = [mapping[i] for i in pred1]\n",
    "translated_pred2 = [mapping[i] for i in pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206df30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train,translated_pred1,target_names=species_names))\n",
    "print(classification_report(y_test,translated_pred2,target_names=species_names))\n",
    "print(model.inertia_)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test,translated_pred2)\n",
    "cf = ConfusionMatrixDisplay(cf_matrix, display_labels= species_names)\n",
    "cf.plot(xticks_rotation='vertical')\n",
    "plt.savefig('plots/den-est-cf.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ce8fca",
   "metadata": {},
   "source": [
    "# Traditional Classification --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2620f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, label):\n",
    "    cvs = []\n",
    "    start = time.time()\n",
    "    knn = KNeighborsClassifier()\n",
    "    n_neighbors = {'n_neighbors': list(range(2,10))}\n",
    "    clf_knn = GridSearchCV(knn,n_neighbors).fit(X,label)\n",
    "    cvs.append(clf_knn)\n",
    "    print(\"KNN done\")\n",
    "    print(\"Time: {0:.2f} seconds\\nBest accuracy:{1:.2f}, Estimator: {2}\\n\".format(time.time()-start,clf_knn.best_score_,clf_knn.best_estimator_))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    svm = SVC(kernel='linear')\n",
    "    kernel = {'C': [0.1, 1, 10, 100]}\n",
    "    clf_svm = GridSearchCV(svm,kernel).fit(X,label)\n",
    "    cvs.append(clf_svm)\n",
    "    print(\"linear SVM done.\")\n",
    "    print(\"Time: {0:.2f} seconds\\nBest accuracy: {1:.2f}, Estimator: {2}\\n\".format(time.time()-start,clf_svm.best_score_,clf_svm.best_estimator_))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    svm = SVC(kernel='rbf')\n",
    "    kernel = {'C': [0.1, 1, 10, 100]}\n",
    "    clf_svm = GridSearchCV(svm,kernel).fit(X,label)\n",
    "    cvs.append(clf_svm)\n",
    "    print(\"Kernel SVM done.\")\n",
    "    print(\"Time: {0:.2f} seconds\\nBest accuracy: {1:.2f}, estimator: {2}\\n\".format(time.time()-start,clf_svm.best_score_,clf_svm.best_estimator_))\n",
    "    \n",
    "    start = time.time()\n",
    "    lr = LogisticRegression(max_iter=10000,random_state=seed)\n",
    "    acc_score_lr = np.mean(cross_val_score(lr,X,label,cv=5))\n",
    "    cvs.append(acc_score_lr)\n",
    "    print(\"LR done\")\n",
    "    print(\"Time: {0:.2f} seconds\\nBest accuracy: {1:.2f}\\n\".format(time.time()-start,acc_score_lr))\n",
    "    \n",
    "    return cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5450fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_Xy(train_pictures)\n",
    "X, kpca = dim_reduction_kernelcosine(X)\n",
    "print(X.shape,'\\n')\n",
    "cv_grid = train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = get_Xy(train_pictures)\n",
    "print(X2.shape)\n",
    "X2, pca = dim_reduction(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X2.shape)\n",
    "cv_grid = train_model(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d2bf9",
   "metadata": {},
   "source": [
    "# Deep Learning -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2249a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_pre_process(image_catalog, og_shape):\n",
    "    X, y = get_Xy(image_catalog)\n",
    "    tenso_X = np.reshape(X,(X.shape[0], og_shape[0], og_shape[1], 3))\n",
    "    tenso_X = tenso_X.astype('float32')\n",
    "    tenso_X = tenso_X / 255.\n",
    "    \n",
    "    y_one_hot = to_categorical(y)\n",
    "    return tenso_X, y_one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = deep_pre_process(train_pictures, size)\n",
    "X_val, y_val = deep_pre_process(valid_pictures, size)\n",
    "X_test, y_test = deep_pre_process(test_pictures, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c474f47",
   "metadata": {},
   "source": [
    "## Neural Network implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(shape,classes):\n",
    "    bird_model = Sequential()\n",
    "    bird_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(shape[1],shape[2],shape[3]),padding='same'))\n",
    "    bird_model.add(LeakyReLU(alpha=0.1))\n",
    "    bird_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "    bird_model.add(Dropout(0.25))\n",
    "    bird_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "    bird_model.add(LeakyReLU(alpha=0.1))\n",
    "    bird_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    bird_model.add(Dropout(0.25))\n",
    "    bird_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "    bird_model.add(LeakyReLU(alpha=0.1))                  \n",
    "    bird_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    bird_model.add(Dropout(0.4))\n",
    "    bird_model.add(Flatten())\n",
    "    bird_model.add(Dense(128, activation='linear'))\n",
    "    bird_model.add(LeakyReLU(alpha=0.1))           \n",
    "    bird_model.add(Dropout(0.3))\n",
    "    bird_model.add(Dense(classes, activation='softmax'))\n",
    "    \n",
    "    bird_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=Adam(),metrics=['accuracy'])\n",
    "    print(bird_model.summary())\n",
    "    return bird_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = num_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ec854",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cnn = build_model(X_train.shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78242304",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_train = clf_cnn.fit(X_train, y_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5931db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = bird_train.history['accuracy']\n",
    "val_accuracy = bird_train.history['val_accuracy']\n",
    "loss = bird_train.history['loss']\n",
    "val_loss = bird_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.savefig('plots/cnn-accuracy.jpg')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.savefig('plots/cnn-loss.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea80f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = clf_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "prediction = np.argmax(clf_cnn.predict(X_test),axis=1)\n",
    "true_y = np.argmax(y_test,axis=1)\n",
    "\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1], '\\n')\n",
    "\n",
    "print(classification_report(true_y,prediction,target_names=species_names))\n",
    "\n",
    "cf_matrix_cnn = confusion_matrix(true_y,prediction)\n",
    "cf_cnn = ConfusionMatrixDisplay(cf_matrix_cnn, display_labels= species_names)\n",
    "cf_cnn.plot(xticks_rotation='vertical')\n",
    "plt.savefig('plots/deep-learn-cf.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
